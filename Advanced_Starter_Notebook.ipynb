{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation\n",
    "import os\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"  # Disable GPU for JAX (Remove if you want to use GPU)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "# deteministic random numbers\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.variable import Real, Integer, Choice, Binary\n",
    "from pymoo.core.mixed import MixedVariableMating, MixedVariableGA, MixedVariableSampling, MixedVariableDuplicateElimination\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling, Sampling\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PolynomialMutation\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from LINKS.Optimization import DifferentiableTools, Tools\n",
    "\n",
    "#load the curves to fit\n",
    "target_curves = np.load('target_curves.npy')\n",
    "\n",
    "PROBLEM_TOOLS = Tools( # we have to define this outside the class due to pymoo deepcopy limitations\n",
    "            device='cpu' # device to run the optimization on\n",
    "        )  \n",
    "PROBLEM_TOOLS.compile() # compile the functions for faster runs\n",
    "\n",
    "class mechanism_synthesis_optimization(ElementwiseProblem):\n",
    "\n",
    "    # When intializing, set the mechanism size and target curve\n",
    "    def __init__(self, target_curve, N = 5):\n",
    "        self.N = N\n",
    "        variables = dict()\n",
    "\n",
    "        # The upper triangular portion of our NxN Connectivity Matrix consists of Nx(N-1)/2 boolean variables:\n",
    "        for i in range(N):\n",
    "            for j in range(i):\n",
    "                variables[\"C\" + str(j) + \"_\" + str(i)] = Binary()\n",
    "\n",
    "        # We Delete C0_1 since we know node 1 is connected to the motor\n",
    "        del variables[\"C0_1\"]\n",
    "\n",
    "        #Our position matrix consists of Nx2 real numbers (cartesian coordinate values) between 0 and 1\n",
    "        for i in range(2*N):\n",
    "            variables[\"X0\" + str(i)] = Real(bounds=(0.0, 1.0))\n",
    "\n",
    "        # Our node type vector consists of N boolean variables (fixed vs non-fixed)\n",
    "        for i in range(N):\n",
    "            variables[\"fixed_nodes\" + str(i)] =  Binary(N)\n",
    "\n",
    "        # Our target node is an integer between 1 and N-1, (any except the motor node).\n",
    "        variables[\"target\"] = Integer(bounds=(1,N-1))\n",
    "\n",
    "        # Set up some variables in the problem class we inherit for pymoo\n",
    "        # n_obj=number of objectives, n_constr=number of constraints\n",
    "        # Our objectives are chamfer distance and material, and they both have constraints.\n",
    "        super().__init__(vars=variables, n_obj=2, n_constr=2)\n",
    "\n",
    "        # Store the target curve point cloud\n",
    "        self.target_curve = target_curve\n",
    "\n",
    "\n",
    "    def convert_1D_to_mech(self, x):\n",
    "        N = self.N\n",
    "\n",
    "        # Get target joints index\n",
    "        target_idx = x[\"target\"]\n",
    "\n",
    "        # Build connectivity matrix from its flattened constitutive variables\n",
    "        C = np.zeros((N,N))\n",
    "        x[\"C0_1\"] = 1\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(i):\n",
    "                # C[i,j] = x[\"C\" + str(j) + \"_\" + str(i)]\n",
    "                C[j,i] = x[\"C\" + str(j) + \"_\" + str(i)]\n",
    "\n",
    "        edges = np.array(np.where(C==1)).T\n",
    "        \n",
    "        # Reshape flattened position matrix to its proper Nx2 shape\n",
    "        x0 = np.array([x[\"X0\" + str(i)] for i in range(2*N)]).reshape([N,2])\n",
    "\n",
    "        # Extract a list of Nodes that are fixed from boolean fixed_nodes vector\n",
    "        fixed_joints = np.where(np.array([x[\"fixed_nodes\" + str(i)] for i in range(N)]))[0].astype(int)\n",
    "\n",
    "        #We fix the motor and original ground node as 0 and 1 respectively in this implementation\n",
    "        motor=np.array([0,1])\n",
    "\n",
    "        return x0, edges, fixed_joints, motor, target_idx\n",
    "\n",
    "    def convert_mech_to_1D(self, x0, edges, fixed_joints, target_idx=None, **kwargs):\n",
    "        # This function assumes motor to be [0, 1] our random mechanism generator automatically does this\n",
    "        N = self.N\n",
    "\n",
    "        # Initialize dictionary to store 1D representation of mechanism\n",
    "        x = {}\n",
    "\n",
    "        # Store target node value\n",
    "        if target_idx is None:\n",
    "            target_idx = x0.shape[0]-1 # Assume last node is the target if not specified\n",
    "            \n",
    "        x[\"target\"] = target_idx\n",
    "\n",
    "        # Store connectivity matrix in its flattened form\n",
    "        C = np.zeros((N,N), dtype=bool)\n",
    "        C[edges[:,0], edges[:,1]] = 1\n",
    "        C[edges[:,1], edges[:,0]] = 1\n",
    "       \n",
    "        for i in range(N):\n",
    "            for j in range(i):\n",
    "                x[\"C\" + str(j) + \"_\" + str(i)] = C[i,j]\n",
    "\n",
    "        del x[\"C0_1\"]\n",
    "        \n",
    "        # Store position matrix in its flattened form\n",
    "        if x0.shape[0] != N:\n",
    "            x0 = np.pad(x0, ((0, N - x0.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "            \n",
    "        for i in range(2*N):\n",
    "            x[\"X0\" + str(i)] = x0.flatten()[i]\n",
    "\n",
    "        # Store fixed nodes in boolean vector form\n",
    "        for i in range(N):\n",
    "            x[\"fixed_nodes\" + str(i)] = (i in fixed_joints) or (i>=N)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        #Convert to mechanism representation\n",
    "        x0, edges, fixed_joints, motor, target_idx = self.convert_1D_to_mech(x)\n",
    "        \n",
    "        # Simulate\n",
    "        distance, material = PROBLEM_TOOLS(x0,\n",
    "                                edges,\n",
    "                                fixed_joints,\n",
    "                                motor,\n",
    "                                self.target_curve,\n",
    "                                target_idx=target_idx\n",
    "                            )\n",
    "\n",
    "        out[\"F\"] = np.array([distance, material])\n",
    "        out[\"G\"] = out[\"F\"] - np.array([0.75, 10.0])  # Constraints: distance <= 0.75, material <= 10.0\n",
    "\n",
    "from LINKS.Optimization import MechanismRandomizer\n",
    "from LINKS.Visualization import MechanismVisualizer\n",
    "\n",
    "from LINKS.Visualization import GAVisualizer\n",
    "from LINKS.Kinematics import MechanismSolver\n",
    "from LINKS.Geometry import CurveEngine\n",
    "\n",
    "from pymoo.indicators.hv import HV\n",
    "ga_visualizer = GAVisualizer()\n",
    "solver = MechanismSolver(device='cpu')\n",
    "curve_engine = CurveEngine(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm Optimisation\n",
    "# from pymoo.algorithms.moo.rnsga2 import RNSGA2\n",
    "\n",
    "''' INIT '''\n",
    "from utils.mechanism_io import load_mechanisms, save_mechanisms\n",
    "\n",
    "''' INIT End '''\n",
    "\n",
    "\n",
    "''' Setup '''\n",
    "NUM_OF_NODES = 7\n",
    "NUM_OF_MECH = 1000\n",
    "NUM_INIT_MECH = NUM_OF_MECH*100\n",
    "NUM_OF_GENERATIONS = 1000\n",
    "\n",
    "ONLY_FIRST_CURVE = False\n",
    "if ONLY_FIRST_CURVE:\n",
    "        curves = [0]\n",
    "else:\n",
    "        curves = range(target_curves.shape[0])\n",
    "\n",
    "TAKE_RANDOM = False\n",
    "if TAKE_RANDOM:\n",
    "    file_name= f'Random_nodes_{NUM_OF_NODES}_mech_{NUM_OF_MECH}_of_{NUM_INIT_MECH}'\n",
    "''' Setup End '''\n",
    "\n",
    "results = []\n",
    "for curve_index in curves:\n",
    "        mechanisms = load_mechanisms(f'{file_name}_curve_{curve_index}.npy')\n",
    "        print(\"Input file:\", f'{file_name}_curve_{curve_index}.npy', \"numer of mechanisms:\", len(mechanisms))\n",
    "\n",
    "        problem = mechanism_synthesis_optimization(target_curves[curve_index], N=NUM_OF_NODES)\n",
    "\n",
    "        initial_population = [problem.convert_mech_to_1D(**mech) for mech in mechanisms]\n",
    "\n",
    "        class sample_from_random(Sampling):\n",
    "                def _do(self, problem, n_samples, **kwargs):\n",
    "                        return np.array([initial_population[i%len(initial_population)] for i in range(n_samples)])\n",
    "\n",
    "        F = problem.evaluate(np.array(initial_population))[0]\n",
    "        print(f'Best Distance Performance In random population: {F[:,0].min()}')\n",
    "        print(f'Best Material Performance In random population: {F[:,1].min()}')\n",
    "\n",
    "        algorithm = NSGA2(pop_size=len(initial_population),\n",
    "                        sampling=sample_from_random(),\n",
    "                        mating=MixedVariableMating(eliminate_duplicates=MixedVariableDuplicateElimination()),\n",
    "                        mutation=PolynomialMutation(prob=0.5),\n",
    "                        eliminate_duplicates=MixedVariableDuplicateElimination())\n",
    "\n",
    "        results.append(minimize(problem,\n",
    "                        algorithm,\n",
    "                        ('n_gen', NUM_OF_GENERATIONS),\n",
    "                        verbose=True,\n",
    "                        save_history=True,\n",
    "                        seed=123\n",
    "                        ))\n",
    "        \n",
    "        # algorithm = RNSGA2(\n",
    "        #         pop_size=100,\n",
    "        #         ref_points=np.atleast_2d(ref_point),\n",
    "        #         sampling=sample_from_random(),\n",
    "        #         mating=MixedVariableMating(eliminate_duplicates=MixedVariableDuplicateElimination()),\n",
    "        #         mutation=PolynomialMutation(prob=0.5),\n",
    "        #         eliminate_duplicates=MixedVariableDuplicateElimination()\n",
    "        #         )\n",
    "                \n",
    "        #         results = minimize(\n",
    "        #         problem,\n",
    "        #         algorithm,\n",
    "        #         ('n_gen', 100),\n",
    "        #         verbose=True,\n",
    "        #         save_history=True,\n",
    "        #         seed=123\n",
    "        # )\n",
    "\n",
    "        if not results[curve_index].X is None:\n",
    "                #Specify reference point\n",
    "                ref_point = np.array([0.75, 10.0])\n",
    "\n",
    "                #Calculate Hypervolume\n",
    "                ind = HV(ref_point)\n",
    "                hypervolume = ind(results[curve_index].F)\n",
    "\n",
    "                #Print and plot\n",
    "                print('Hyper Volume ~ %f' %(hypervolume))\n",
    "                ga_visualizer.plot_HV(results[curve_index].F, ref_point, objective_labels=['Distance', 'Material']) #use the plot_HV function from utils\n",
    "        else:\n",
    "                print('Did Not Find Solutions!!')\n",
    "\n",
    "\n",
    "# Write results from GA to file\n",
    "for curve_index in curves:\n",
    "    # add out population to submission\n",
    "    mechanisms = []\n",
    "    if not results[curve_index].X is None:\n",
    "        for j in range(results[curve_index].X.shape[0]):\n",
    "            if not isinstance(results[curve_index].X, dict):\n",
    "                x0_member, edges, fixed_joints, motor, target_idx  = problem.convert_1D_to_mech(results[curve_index].X[j])\n",
    "            else:\n",
    "                x0_member, edges, fixed_joints, motor, target_idx  = problem.convert_1D_to_mech(results[curve_index].X)\n",
    "            \n",
    "            mech = {\n",
    "                'x0': x0_member,\n",
    "                'edges': edges,\n",
    "                'fixed_joints': fixed_joints,\n",
    "                'motor': motor,\n",
    "                #'target_joint': target_idx # ignore for now\n",
    "            }\n",
    "            mechanisms.append(mech)\n",
    "    file_name_temp = f'GA_nodes_{NUM_OF_NODES}_mech_{NUM_OF_MECH}_NUM_OF_GENERATIONS_{NUM_OF_GENERATIONS}'\n",
    "    save_mechanisms(mechanisms, f'{file_name_temp}_curve_{curve_index}.npy', overwrite=True)\n",
    "    print(file_name)\n",
    "file_name = file_name_temp\n",
    "print(len(mechanisms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mechanisms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Optimization (material)\n",
    "''' INIT '''\n",
    "from LINKS.Optimization import DifferentiableTools\n",
    "from utils.mechanism_io import load_mechanisms, save_mechanisms\n",
    "\n",
    "differentiable_optimization_tools = DifferentiableTools(\n",
    "    device='cpu' # device to run the optimization on\n",
    ")  \n",
    "differentiable_optimization_tools.compile() # compile the functions for faster runs\n",
    "''' INIT End '''\n",
    "\n",
    "\n",
    "''' Setup '''\n",
    "STEP_SIZE = 4e-4\n",
    "NUM_OF_STEPS = 1000 #default 1000\n",
    "''' Setup End '''\n",
    "\n",
    "\n",
    "\n",
    "for curve_index in curves:\n",
    "    x0s = []\n",
    "    edges = []\n",
    "    fixed_joints = []\n",
    "    motors = []\n",
    "    #mechanisms = load_mechanisms(f'mechanisms_curve_{curve_index}_nodes_{NUM_OF_NODES}_mech_{NUM_OF_MECH}.npy')\n",
    "    mechanisms = load_mechanisms(f'{file_name}_curve_{curve_index}.npy')\n",
    "    print(\"Input file:\", f'{file_name}_curve_{curve_index}.npy', \"numer of mechanisms:\", len(mechanisms))\n",
    "    # print(mechanisms)\n",
    "    for mech in mechanisms:\n",
    "        x0s.append(mech['x0'])\n",
    "        edges.append(mech['edges'])\n",
    "        fixed_joints.append(mech['fixed_joints'])\n",
    "        motors.append(mech['motor'])\n",
    "\n",
    "    x = x0s.copy()\n",
    "\n",
    "    # keep track of which members are done optimizing\n",
    "    done_optimizing = np.zeros(len(x), dtype=bool)\n",
    "\n",
    "    x_last = x.copy()\n",
    "\n",
    "    for step in trange(NUM_OF_STEPS):\n",
    "        \n",
    "        # get current distances, materials and gradients\n",
    "        distances, materials, distance_grads, material_grads = differentiable_optimization_tools(\n",
    "            x,\n",
    "            edges,\n",
    "            fixed_joints,\n",
    "            motors,\n",
    "            target_curves[curve_index],\n",
    "        )\n",
    "        \n",
    "        # only update members that are valid and not done optimizing\n",
    "        valids = np.where(np.logical_and(distances <= 0.75, materials <= 10.0))[0]\n",
    "        invalids = np.where(~np.logical_and(distances <= 0.75, materials <= 10.0))[0]\n",
    "        \n",
    "        # if a member is invalid, revert to last step and mark as done optimizing\n",
    "        for i in invalids:\n",
    "            done_optimizing[i] = True\n",
    "            x[i] = x_last[i]\n",
    "        \n",
    "        # keep a copy of last step\n",
    "        x_last = x.copy()\n",
    "\n",
    "        # update valid members\n",
    "        for i in valids:\n",
    "            if done_optimizing[i]:\n",
    "                continue\n",
    "            x[i] = x[i] - STEP_SIZE * material_grads[i] #distance_grads[i]#distance_grads[i]#material_grads\n",
    "            # x[i] = x[i] - STEP_SIZE * distance_grads[i]\n",
    "            \n",
    "        if np.all(done_optimizing):\n",
    "            print(f'All members are done optimizing at step {step}')\n",
    "            break\n",
    "\n",
    "\n",
    "    F_before = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            x0s,\n",
    "            edges,\n",
    "            fixed_joints,\n",
    "            motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    F_after = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            x,\n",
    "            edges,\n",
    "            fixed_joints,\n",
    "            motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    combined_x0s = x0s + x\n",
    "    combined_edges = edges + edges\n",
    "    combined_fixed_joints = fixed_joints + fixed_joints\n",
    "    combined_motors = motors + motors\n",
    "\n",
    "    F_combo = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            combined_x0s,\n",
    "            combined_edges,\n",
    "            combined_fixed_joints,\n",
    "            combined_motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    ref = np.array([0.75, 10.0])\n",
    "    ind = HV(ref)\n",
    "\n",
    "    hv_before = ind(F_before)\n",
    "    hv_after = ind(F_after)\n",
    "    hv_combo = ind(F_combo)\n",
    "\n",
    "    # VIZUALIZE\n",
    "    print(f'Hypervolume before gradient optimization: {hv_before:.4f}, after optimization:  {hv_after:.4f}, combined:  {hv_combo:.4f}')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title('Before Gradient Optimization')\n",
    "    ga_visualizer.plot_HV(F_before, ref, objective_labels=['Distance', 'Material'], ax=ax1)\n",
    "\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title('After Gradient Optimization')\n",
    "    ga_visualizer.plot_HV(F_after, ref, objective_labels=['Distance', 'Material'], ax=ax2)\n",
    "\n",
    "    ax3 = axes[2]\n",
    "    ax3.set_title('Combined')\n",
    "    ga_visualizer.plot_HV(F_combo, ref, objective_labels=['Distance', 'Material'], ax=ax3)\n",
    "\n",
    "\n",
    "    # capture x/y limits from combined plot\n",
    "    xlim = ax3.get_xlim()\n",
    "    ylim = ax3.get_ylim()\n",
    "    #and apply for the first\n",
    "    ax1.set_xlim(xlim)\n",
    "    ax1.set_ylim(ylim)\n",
    "    ax2.set_xlim(xlim)\n",
    "    ax2.set_ylim(ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # WRITE TO FILE\n",
    "    mechanisms = []\n",
    "    mech = {}\n",
    "    for i in range(len(combined_x0s)):\n",
    "        mech = {\n",
    "                'x0': combined_x0s[i],\n",
    "                'edges': combined_edges[i],\n",
    "                'fixed_joints': combined_fixed_joints[i],\n",
    "                'motor': combined_motors[i],\n",
    "                #'target_joint': target_idx[i]\n",
    "            }\n",
    "        mechanisms.append(mech)\n",
    "\n",
    "    file_name_temp = f'GD_material_nodes_{NUM_OF_NODES}_mech_{NUM_OF_MECH}_STEP_SIZE_{STEP_SIZE}_NUM_OF_STEPS_{NUM_OF_STEPS}'\n",
    "\n",
    "    save_mechanisms(mechanisms, f'{file_name_temp}_curve_{curve_index}.npy', overwrite=True)\n",
    "    # print(mechanisms)\n",
    "    print(file_name)\n",
    "\n",
    "file_name = file_name_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Optimization (distance)\n",
    "''' INIT '''\n",
    "from LINKS.Optimization import DifferentiableTools\n",
    "from utils.mechanism_io import load_mechanisms, save_mechanisms\n",
    "\n",
    "differentiable_optimization_tools = DifferentiableTools(\n",
    "    device='cpu' # device to run the optimization on\n",
    ")  \n",
    "differentiable_optimization_tools.compile() # compile the functions for faster runs\n",
    "''' INIT End '''\n",
    "\n",
    "\n",
    "''' Setup '''\n",
    "# # NUM_OF_NODES = 7\n",
    "# # NUM_OF_MECH = 100\n",
    "STEP_SIZE = STEP_SIZE\n",
    "NUM_OF_STEPS = NUM_OF_STEPS #default 1000\n",
    "''' Setup End '''\n",
    "\n",
    "\n",
    "\n",
    "for curve_index in curves:\n",
    "    x0s = []\n",
    "    edges = []\n",
    "    fixed_joints = []\n",
    "    motors = []\n",
    "    #mechanisms = load_mechanisms(f'mechanisms_curve_{curve_index}_nodes_{NUM_OF_NODES}_mech_{NUM_OF_MECH}.npy')\n",
    "    mechanisms = load_mechanisms(f'{file_name}_curve_{curve_index}.npy')\n",
    "    print(\"Input file:\", f'{file_name}_curve_{curve_index}.npy', \"numer of mechanisms:\", len(mechanisms))\n",
    "\n",
    "    for mech in mechanisms:\n",
    "        x0s.append(mech['x0'])\n",
    "        edges.append(mech['edges'])\n",
    "        fixed_joints.append(mech['fixed_joints'])\n",
    "        motors.append(mech['motor'])\n",
    "\n",
    "    x = x0s.copy()\n",
    "\n",
    "    # keep track of which members are done optimizing\n",
    "    done_optimizing = np.zeros(len(x), dtype=bool)\n",
    "\n",
    "    x_last = x.copy()\n",
    "\n",
    "    for step in trange(NUM_OF_STEPS):\n",
    "        \n",
    "        # get current distances, materials and gradients\n",
    "        distances, materials, distance_grads, material_grads = differentiable_optimization_tools(\n",
    "            x,\n",
    "            edges,\n",
    "            fixed_joints,\n",
    "            motors,\n",
    "            target_curves[curve_index],\n",
    "        )\n",
    "        \n",
    "        # only update members that are valid and not done optimizing\n",
    "        valids = np.where(np.logical_and(distances <= 0.75, materials <= 10.0))[0]\n",
    "        invalids = np.where(~np.logical_and(distances <= 0.75, materials <= 10.0))[0]\n",
    "        \n",
    "        # if a member is invalid, revert to last step and mark as done optimizing\n",
    "        for i in invalids:\n",
    "            done_optimizing[i] = True\n",
    "            x[i] = x_last[i]\n",
    "        \n",
    "        # keep a copy of last step\n",
    "        x_last = x.copy()\n",
    "\n",
    "        # update valid members\n",
    "        for i in valids:\n",
    "            if done_optimizing[i]:\n",
    "                continue\n",
    "            x[i] = x[i] - STEP_SIZE * distance_grads[i]\n",
    "            \n",
    "        if np.all(done_optimizing):\n",
    "            print(f'All members are done optimizing at step {step}')\n",
    "            break\n",
    "\n",
    "\n",
    "    F_before = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            x0s,\n",
    "            edges,\n",
    "            fixed_joints,\n",
    "            motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    F_after = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            x,\n",
    "            edges,\n",
    "            fixed_joints,\n",
    "            motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    combined_x0s = x0s + x\n",
    "    combined_edges = edges + edges\n",
    "    combined_fixed_joints = fixed_joints + fixed_joints\n",
    "    combined_motors = motors + motors\n",
    "\n",
    "    F_combo = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            combined_x0s,\n",
    "            combined_edges,\n",
    "            combined_fixed_joints,\n",
    "            combined_motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    ref = np.array([0.75, 10.0])\n",
    "    ind = HV(ref)\n",
    "\n",
    "    hv_before = ind(F_before)\n",
    "    hv_after = ind(F_after)\n",
    "    hv_combo = ind(F_combo)\n",
    "\n",
    "    # VIZUALIZE\n",
    "    print(f'Hypervolume before gradient optimization: {hv_before:.4f}, after optimization:  {hv_after:.4f}, combined:  {hv_combo:.4f}')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title('Before Gradient Optimization')\n",
    "    ga_visualizer.plot_HV(F_before, ref, objective_labels=['Distance', 'Material'], ax=ax1)\n",
    "\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title('After Gradient Optimization')\n",
    "    ga_visualizer.plot_HV(F_after, ref, objective_labels=['Distance', 'Material'], ax=ax2)\n",
    "\n",
    "    ax3 = axes[2]\n",
    "    ax3.set_title('Combined')\n",
    "    ga_visualizer.plot_HV(F_combo, ref, objective_labels=['Distance', 'Material'], ax=ax3)\n",
    "\n",
    "\n",
    "    # capture x/y limits from combined plot\n",
    "    xlim = ax3.get_xlim()\n",
    "    ylim = ax3.get_ylim()\n",
    "    #and apply for the first\n",
    "    ax1.set_xlim(xlim)\n",
    "    ax1.set_ylim(ylim)\n",
    "    ax2.set_xlim(xlim)\n",
    "    ax2.set_ylim(ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # WRITE TO FILE\n",
    "    mechanisms = []\n",
    "    mech = {}\n",
    "    for i in range(len(combined_x0s)):\n",
    "        mech = {\n",
    "                'x0': combined_x0s[i],\n",
    "                'edges': combined_edges[i],\n",
    "                'fixed_joints': combined_fixed_joints[i],\n",
    "                'motor': combined_motors[i],\n",
    "                #'target_joint': target_idx[i]\n",
    "            }\n",
    "        mechanisms.append(mech)\n",
    "\n",
    "    file_name_temp = f'GD_distance_nodes_{NUM_OF_NODES}_mech_{NUM_OF_MECH}_STEP_SIZE_{STEP_SIZE}_NUM_OF_STEPS_{NUM_OF_STEPS}'\n",
    "    save_mechanisms(mechanisms, f'{file_name_temp}_curve_{curve_index}.npy', overwrite=True)\n",
    "    print(file_name)\n",
    "\n",
    "file_name = file_name_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission from file\n",
    "from LINKS.CP import make_empty_submission, evaluate_submission\n",
    "\n",
    "# Genetic Algorithm Optimisation\n",
    "from utils.mechanism_io import load_mechanisms\n",
    "\n",
    "submission = make_empty_submission()\n",
    "curves = [0,1,2,3,4,5]\n",
    "\n",
    "for curve_index in curves:\n",
    "\n",
    "    mechanisms = load_mechanisms(f'{file_name}_curve_{curve_index}.npy')\n",
    "    print(\"Input file:\", f'{file_name}_curve_{curve_index}.npy', \"numer of mechanisms:\", len(mechanisms))\n",
    "    \n",
    "    k = curve_index + 1\n",
    "    for mech in mechanisms:\n",
    "        submission[f'Problem {k}'].append(mech)\n",
    "            \n",
    "#\n",
    "np.save(f'my_full_submission_{file_name}.npy', submission) \n",
    "evaluation = evaluate_submission(submission)\n",
    "evaluation\n",
    "# submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Sometimes the mechanisms are close to locking, which results in gradients exploding and in these cases the `DifferentiableTools` will return inifity results. You can ignore these since the `Tools` class will still simulate them eventhough the gradients are near singular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine mechanism from 2 submission files\n",
    "# file_path = f'my_full_submission_combined.npy'\n",
    "file_path = \"my_full_submission.npy\"\n",
    "file_path2 = f'my_full_submission_GA_nodes_7_mech_1000_NUM_OF_GENERATIONS_1000.npy'\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "print('Loading:', file_path)\n",
    "try:\n",
    "    data = np.load(file_path, allow_pickle=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f'Failed to load {file_path}: {e}')\n",
    "try:\n",
    "    data2 = np.load(file_path2, allow_pickle=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f'Failed to load {file_path2}: {e}')\n",
    "\n",
    "data.item()['Problem 1'] [0] \n",
    "\n",
    "for curve_index in curves:\n",
    "    x01 = []\n",
    "    edges1 = []\n",
    "    fixed_joints1 = []\n",
    "    motors1 = []\n",
    "    x02 = []\n",
    "    edges2 = []\n",
    "    fixed_joints2 = []\n",
    "    motors2 = []\n",
    "    mechanisms = data.item()[f'Problem {curve_index +1}']\n",
    "    mechanisms2 = data2.item()[f'Problem {curve_index +1}']\n",
    "\n",
    "\n",
    "    for mech in mechanisms:\n",
    "        x01.append(mech['x0'])\n",
    "        edges1.append(mech['edges'])\n",
    "        fixed_joints1.append(mech['fixed_joints'])\n",
    "        motors1.append(mech['motor'])\n",
    "    for mech in mechanisms2:\n",
    "        x02.append(mech['x0'])\n",
    "        edges2.append(mech['edges'])\n",
    "        fixed_joints2.append(mech['fixed_joints'])\n",
    "        motors2.append(mech['motor'])\n",
    "\n",
    "\n",
    "\n",
    "    F_before = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            x01,\n",
    "            edges1,\n",
    "            fixed_joints1,\n",
    "            motors1,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "        \n",
    "    F_after = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            x02,\n",
    "            edges2,\n",
    "            fixed_joints2,\n",
    "            motors2,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "    \n",
    "    combined_x0s = x01 + x02\n",
    "    combined_edges = edges1 + edges2\n",
    "    combined_fixed_joints = fixed_joints1 + fixed_joints2\n",
    "    combined_motors = motors1 + motors2\n",
    "\n",
    "    F_combo = np.array(\n",
    "        PROBLEM_TOOLS(\n",
    "            combined_x0s,\n",
    "            combined_edges,\n",
    "            combined_fixed_joints,\n",
    "            combined_motors,\n",
    "            target_curves[curve_index],\n",
    "        )).T\n",
    "        \n",
    "    ref = np.array([0.75, 10.0])\n",
    "    ind = HV(ref)\n",
    "\n",
    "    hv_before = ind(F_before)\n",
    "    hv_after = ind(F_after)\n",
    "    hv_combo = ind(F_combo)\n",
    "\n",
    "    # VIZUALIZE\n",
    "    print(f'Hypervolume first file: {hv_before:.4f}, second file:  {hv_after:.4f}, combined:  {hv_combo:.4f}')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title('First file')\n",
    "    ga_visualizer.plot_HV(F_before, ref, objective_labels=['Distance', 'Material'], ax=ax1)\n",
    "\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title('Second file')\n",
    "    ga_visualizer.plot_HV(F_after, ref, objective_labels=['Distance', 'Material'], ax=ax2)\n",
    "\n",
    "    ax3 = axes[2]\n",
    "    ax3.set_title('Combined')\n",
    "    ga_visualizer.plot_HV(F_combo, ref, objective_labels=['Distance', 'Material'], ax=ax3)\n",
    "\n",
    "\n",
    "    # capture x/y limits from combined plot\n",
    "    xlim = ax3.get_xlim()\n",
    "    ylim = ax3.get_ylim()\n",
    "    #and apply for the first\n",
    "    ax1.set_xlim(xlim)\n",
    "    ax1.set_ylim(ylim)\n",
    "    ax2.set_xlim(xlim)\n",
    "    ax2.set_ylim(ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # WRITE TO FILE\n",
    "    mechanisms = []\n",
    "    mech = {}\n",
    "    for i in range(len(combined_x0s)):\n",
    "        mech = {\n",
    "                'x0': combined_x0s[i],\n",
    "                'edges': combined_edges[i],\n",
    "                'fixed_joints': combined_fixed_joints[i],\n",
    "                'motor': combined_motors[i],\n",
    "                #'target_joint': target_idx[i]\n",
    "            }\n",
    "        mechanisms.append(mech)\n",
    "\n",
    "    file_name_temp = f'my_full_submission_combined'\n",
    "    save_mechanisms(mechanisms, f'{file_name_temp}_curve_{curve_index}.npy', overwrite=True)\n",
    "    print(file_name)\n",
    "\n",
    "file_name = file_name_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_submissions_best(sub_paths, output_path, num_per_curve=1000, target_curves_arg=None, problem_tools=None):\n",
    "    \"\"\"Merge multiple submission .npy files and keep up to `num_per_curve` best mechanisms per curve.\n",
    "\n",
    "    Selection heuristic: sort by distance (ascending) then material (ascending).\n",
    "\n",
    "    Parameters\n",
    "    - sub_paths: list of paths to .npy submission files (each saved via `np.save(..., submission)`).\n",
    "    - output_path: path to write merged submission .npy\n",
    "    - num_per_curve: maximum mechanisms to keep per curve/problem\n",
    "    - target_curves_arg: optional array of target curves; if None the function will try to use variable `target_curves` from the notebook globals.\n",
    "    - problem_tools: optional PROBLEM_TOOLS-like callable; if None the function will try to use `PROBLEM_TOOLS` from globals.\n",
    "\n",
    "    Returns the merged submission dict.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from LINKS.CP import make_empty_submission\n",
    "\n",
    "    # resolve target curves and tools from globals if not provided\n",
    "    if target_curves_arg is None:\n",
    "        target_curves_arg = globals().get('target_curves')\n",
    "        if target_curves_arg is None:\n",
    "            raise RuntimeError('target_curves not provided and not found in globals')\n",
    "    if problem_tools is None:\n",
    "        problem_tools = globals().get('PROBLEM_TOOLS')\n",
    "        if problem_tools is None:\n",
    "            raise RuntimeError('PROBLEM_TOOLS not provided and not found in globals')\n",
    "\n",
    "    # load submissions\n",
    "    submissions = []\n",
    "    for p in sub_paths:\n",
    "        arr = np.load(p, allow_pickle=True)\n",
    "        try:\n",
    "            sub = arr.item()\n",
    "        except Exception:\n",
    "            # If saved as array-like of object, try to convert to dict\n",
    "            sub = arr.tolist() if hasattr(arr, 'tolist') else dict(arr)\n",
    "        submissions.append(sub)\n",
    "\n",
    "    # collect all problem keys (e.g., 'Problem 1', ...)\n",
    "    all_keys = []\n",
    "    for sub in submissions:\n",
    "        for k in sub.keys():\n",
    "            if k not in all_keys:\n",
    "                all_keys.append(k)\n",
    "\n",
    "    merged = make_empty_submission()\n",
    "\n",
    "    def mech_key(mech):\n",
    "        # deterministic key for deduplication\n",
    "        try:\n",
    "            x0 = np.asarray(mech.get('x0'))\n",
    "            edges = np.asarray(mech.get('edges'))\n",
    "            fj = np.asarray(mech.get('fixed_joints'))\n",
    "            motor = np.asarray(mech.get('motor')) if mech.get('motor') is not None else None\n",
    "            return (tuple(np.round(x0.flatten(), 8).tolist()), tuple(map(tuple, edges.tolist())) , tuple(np.round(fj.flatten(), 8).tolist()), None if motor is None else tuple(np.round(motor.flatten(),8).tolist()))\n",
    "        except Exception:\n",
    "            return repr(mech)\n",
    "\n",
    "    for key in sorted(all_keys):\n",
    "        # parse curve index from key like 'Problem 1' -> index 0\n",
    "        try:\n",
    "            curve_idx = int(''.join([c for c in key if c.isdigit()])) - 1\n",
    "        except Exception:\n",
    "            # fallback - if we can't determine index, iterate sequentially\n",
    "            curve_idx = 0\n",
    "\n",
    "        # build combined list from all submissions for this key\n",
    "        combined = []\n",
    "        for sub in submissions:\n",
    "            if key in sub:\n",
    "                combined.extend(sub[key])\n",
    "\n",
    "        # deduplicate\n",
    "        unique = []\n",
    "        seen = set()\n",
    "        for mech in combined:\n",
    "            k = mech_key(mech)\n",
    "            if k in seen:\n",
    "                continue\n",
    "            seen.add(k)\n",
    "            unique.append(mech)\n",
    "\n",
    "        if len(unique) == 0:\n",
    "            merged[key] = []\n",
    "            continue\n",
    "\n",
    "        # prepare arrays for evaluation\n",
    "        x0s = []\n",
    "        edges = []\n",
    "        fixed_joints = []\n",
    "        motors = []\n",
    "        for mech in unique:\n",
    "            x0s.append(mech.get('x0'))\n",
    "            edges.append(mech.get('edges'))\n",
    "            fixed_joints.append(mech.get('fixed_joints'))\n",
    "            motors.append(mech.get('motor') if 'motor' in mech else mech.get('motors') if 'motors' in mech else None)\n",
    "\n",
    "        # Evaluate using PROBLEM_TOOLS; handle single-item edge cases\n",
    "        try:\n",
    "            res = np.array(problem_tools(x0s, edges, fixed_joints, motors, target_curves_arg[curve_idx])).T\n",
    "        except Exception:\n",
    "            # Try alternative call signature without list-wrapping\n",
    "            res = np.array(problem_tools(np.array(x0s), edges, fixed_joints, motors, target_curves_arg[curve_idx])).T\n",
    "\n",
    "        if res.ndim == 1:\n",
    "            res = res.reshape(1, -1)\n",
    "        distances = res[:, 0]\n",
    "        materials = res[:, 1]\n",
    "\n",
    "        # sort by distance then material\n",
    "        order = np.lexsort((materials, distances))\n",
    "\n",
    "        top_idx = order[:min(num_per_curve, len(unique))]\n",
    "        selected = [unique[i] for i in top_idx]\n",
    "\n",
    "        merged[key] = selected\n",
    "\n",
    "    # save merged submission\n",
    "    np.save(output_path, merged)\n",
    "    print(f\"Saved merged submission to: {output_path}\")\n",
    "    # return merged dict\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# merged = merge_submissions_best(['my_full_submission_fileA.npy', 'my_full_submission_fileB.npy'], 'my_merged_top1000.npy', num_per_curve=1000)\n",
    "# print({k: len(v) for k, v in merged.items()})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
